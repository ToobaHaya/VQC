{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from google.colab import files\n",
        "from sklearn.model_selection import train_test_split\n",
        "from qiskit_machine_learning.algorithms.classifiers import VQC\n",
        "from qiskit.circuit.library import ZZFeatureMap, TwoLocal\n",
        "from qiskit_algorithms.optimizers import COBYLA\n",
        "from sklearn.metrics import accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "from qiskit_aer import AerSimulator\n",
        "from qiskit_ibm_runtime import QiskitRuntimeService, SamplerV2 as Sampler\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# 1. Create binary data\n",
        "n_samples = 100\n",
        "n_features = 3\n",
        "data = np.random.randint(2, size=(n_samples, n_features))\n",
        "labels = np.random.randint(2, size=n_samples)\n",
        "optimizer = COBYLA(maxiter=100)\n",
        "\n",
        "\n",
        "# --- Prompt for IBM credentials and backend ---\n",
        "api_key = input('Enter your IBM Quantum API key: ')\n",
        "instance_name= input('Enter your Instance name: ')\n",
        "backend_name = input('Enter backend name (e.g., ibm_brisbane): ')\n",
        "\n",
        "# --- Try to connect to IBM Quantum backend ---\n",
        "# --- Authenticate & get backend ---\n",
        "try:\n",
        "    service = QiskitRuntimeService(channel=\"ibm_cloud\", token=api_key, instance=instance_name)\n",
        "    backend = service.backend(backend_name)\n",
        "    sampler = Sampler(backend)\n",
        "    print(f\"‚úÖ Connected to {backend_name}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error accessing IBM backend: {e}\")\n",
        "    print(\"Falling back to local AerSimulator.\")\n",
        "    backend = AerSimulator()\n",
        "# Upload\n",
        "uploaded = files.upload()\n",
        "\n",
        "if uploaded:\n",
        "    filename = next(iter(uploaded))\n",
        "    df = pd.read_csv(filename, sep=None, engine='python')\n",
        "\n",
        "    print(\"üìÑ File columns:\", df.columns)\n",
        "\n",
        "    # Try to remove unwanted index column\n",
        "    if 'Unnamed: 0' in df.columns and df.shape[1] == 2:\n",
        "        df = df.drop(columns='Unnamed: 0')\n",
        "\n",
        "    if df.shape[1] >= 2:\n",
        "        data = df.iloc[:, :-1].values\n",
        "        labels = df.iloc[:, -1].values\n",
        "        print(\"‚úÖ Clean data loaded.\")\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è Not enough columns, using random data.\")\n",
        "        data = np.random.randint(2, size=(n_samples, n_features))\n",
        "        labels = np.random.randint(2, size=n_samples)\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è No file uploaded. Using random binary data.\")\n",
        "    data = np.random.randint(2, size=(n_samples, n_features))\n",
        "    labels = np.random.randint(2, size=n_samples)\n",
        "\n",
        "print(f\"Data shape: {data.shape}, Labels shape: {labels.shape}\")\n",
        "\n",
        "\n",
        "# Split into training and testing sets\n",
        "train_data, test_data, train_labels, test_labels = train_test_split(\n",
        "    data, labels, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "\n",
        "print(f\"Number of training samples: {len(train_data)}\")\n",
        "print(f\"Number of testing samples: {len(test_data)}\")\n",
        "print(f\"Data shape: {train_data.shape}\") # Should be (n_samples, 2) for 2 features\n",
        "\n",
        "\n",
        "# 4. Create quantum model\n",
        "feature_map = ZZFeatureMap(n_features)\n",
        "ansatz = TwoLocal(n_features, ['ry', 'rz'], 'cz', reps=3)\n",
        "\n",
        "vqc = VQC(\n",
        "    feature_map=feature_map,\n",
        "    ansatz=ansatz,\n",
        "    loss='cross_entropy',\n",
        "    optimizer=optimizer\n",
        ")\n",
        "\n",
        "# 5. Train and evaluate\n",
        "vqc.fit(train_data, train_labels)\n",
        "\n",
        "# 2. Make predictions\n",
        "train_preds = vqc.predict(train_data)\n",
        "test_preds = vqc.predict(test_data)\n",
        "\n",
        "# 3. Calculate accuracy\n",
        "train_accuracy = accuracy_score(train_labels, train_preds)\n",
        "test_accuracy = accuracy_score(test_labels, test_preds)\n",
        "\n",
        "# 4. Print results\n",
        "print(\"Train accuracy:\", train_accuracy)\n",
        "print(\"Test accuracy:\", test_accuracy)\n",
        "\n",
        "# (Optional) Check predicted vs. true labels\n",
        "print(\"Test predictions:\", test_preds)\n",
        "print(\"Test true labels:\", test_labels)\n",
        "\n",
        "print(classification_report(test_labels, test_preds))\n",
        "\n",
        "# Plot\n",
        "plt.bar(['Train Accuracy', 'Test Accuracy'], [train_accuracy, test_accuracy], color=['blue', 'green'])\n",
        "plt.ylim(0, 1)\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"VQC Classification Accuracy\")\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.6)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "cNou-dummUcd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}